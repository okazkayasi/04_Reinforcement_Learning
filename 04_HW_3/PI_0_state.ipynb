{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox\n",
    "import numpy as np\n",
    "from math import ceil, log\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_states = 30\n",
    "probs = np.zeros((2, number_of_states, number_of_states))\n",
    "\n",
    "\n",
    "# this are terminal states\n",
    "probs[0, 0, -1] = 1\n",
    "probs[1, 0, 0] = 1\n",
    "\n",
    "\n",
    "# to go left with action 0\n",
    "for i in range(1, number_of_states):\n",
    "    probs[0, i, i-1] = 1\n",
    "    \n",
    "# to go right with action 1\n",
    "for i in range(1, number_of_states-1):\n",
    "    probs[1, i, i+1] = 1\n",
    "\n",
    "    \n",
    "probs[1, -1, -1] = 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewards is action and state and also next state based \n",
    "\n",
    "rewards = np.zeros((2, number_of_states, number_of_states))\n",
    "\n",
    "rewards[0,:,:] = -1\n",
    "rewards[1,:,:] = 1\n",
    "\n",
    "\n",
    "rewards[0,1,0] = 999999\n",
    "\n",
    "\n",
    "rewards\n",
    "\n",
    "gamma = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = mdptoolbox.mdp.PolicyIteration(probs, rewards, gamma, eval_type=1)\n",
    "pi.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyDict = {'gamma':0.75}\n",
    "states = []\n",
    "for i in range(number_of_states):\n",
    "    dicted = {}\n",
    "    dicted['id'] = i\n",
    "    \n",
    "    \n",
    "    actions = []\n",
    "    for act in range(2):\n",
    "        act_dict = {}\n",
    "        \n",
    "        tr_dict = {}\n",
    "        tr_dict['id'] = 0\n",
    "        to = np.where(probs[act, i, :])[0][0]\n",
    "        tr_dict['probability'] = probs[act, i, to] \n",
    "        tr_dict['reward'] = rewards[act, i, to]\n",
    "        tr_dict['to'] = to\n",
    "        tr_list = []\n",
    "        tr_list.append(tr_dict)\n",
    "        act_dict['transitions'] = tr_list \n",
    "        act_dict['id'] = act\n",
    "        actions.append(act_dict)\n",
    "        \n",
    "    \n",
    "    dicted['actions'] = actions\n",
    "    \n",
    "    states.append(dicted)\n",
    "states\n",
    "\n",
    "pyDict['states'] = states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data30.json', 'w') as outfile:\n",
    "    json.dump(pyDict, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
